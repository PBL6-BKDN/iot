import asyncio
import base64
import json
import tempfile
import time
import threading
from typing import Optional, Callable, Dict, Any
import sounddevice as sd
import paho.mqtt.client as mqtt
from pydub import AudioSegment
import os
import soundfile as sf
import numpy as np

from module.vad import VoiceActivityDetector
from navigation.speech.voice_speaker import VoiceSpeaker
from config import SILENCE_THRESHOLD, SILENCE_DURATION, MIN_SPEECH_DURATION
from log import setup_logger
from config import BASE_DIR, MAX_AMP
logger = setup_logger(__name__)


class VoiceStreamer:
    """Class ƒë·ªÉ ghi √¢m v√† g·ª≠i √¢m thanh qua MQTT ho·∫∑c HTTP"""

    def __init__(self, mic_index: int, sample_rate: int = 48000, chunk_duration_ms: int = 100):
        """
        Args:
            mic_name: T√™n microphone ƒë·ªÉ t√¨m device
            sample_rate: T·∫ßn s·ªë l·∫•y m·∫´u √¢m thanh
            chunk_duration_ms: Th·ªùi gian m·ªói chunk (ms) cho real-time streaming
        """
        self.mic_index = mic_index
        self.sample_rate = sample_rate
        self.chunk_duration_ms = chunk_duration_ms
        self.chunk_samples = int(sample_rate * chunk_duration_ms / 1000.0)
        self.is_listening = False
        self.listening_thread = None

        # Voice Activity Detector
        self.vad = VoiceActivityDetector(
            sample_rate=sample_rate,
            silence_threshold=SILENCE_THRESHOLD,  # ƒêi·ªÅu ch·ªânh theo m√¥i tr∆∞·ªùng
            silence_duration=SILENCE_DURATION,
            min_speech_duration=MIN_SPEECH_DURATION
        )

        # Callback functions
        self.on_speech_start = None
        self.on_speech_complete = None
        self.on_speech_data = None

        print(f"üé§ VoiceStreamer initialized - Mic index: {self.mic_index}")

    def set_callbacks(self, on_speech_start: Callable = None,
                      on_speech_complete: Callable = None,
                      on_speech_data: Callable = None):
        """
        Thi·∫øt l·∫≠p callback functions

        Args:
            on_speech_start: G·ªçi khi b·∫Øt ƒë·∫ßu ph√°t hi·ªán gi·ªçng n√≥i
            on_speech_complete: G·ªçi khi ho√†n t·∫•t thu √¢m (audio_data, duration)
            on_speech_data: G·ªçi m·ªói chunk √¢m thanh (audio_chunk, timestamp, status)
        """
        self.on_speech_start = on_speech_start
        self.on_speech_complete = on_speech_complete
        self.on_speech_data = on_speech_data

    def start_listening(self):
        """B·∫Øt ƒë·∫ßu l·∫Øng nghe li√™n t·ª•c"""
        if self.is_listening:
            print("‚ö†Ô∏è ƒêang l·∫Øng nghe r·ªìi!")
            return

        self.is_listening = True
        self.listening_thread = threading.Thread(target=self._listening_loop)
        self.listening_thread.start()
        print("üëÇ B·∫Øt ƒë·∫ßu l·∫Øng nghe li√™n t·ª•c...")

    def stop_listening(self):
        """D·ª´ng l·∫Øng nghe"""
        self.is_listening = False
        if self.listening_thread:
            self.listening_thread.join()
        print("‚èπÔ∏è D·ª´ng l·∫Øng nghe")

    def _listening_loop(self):
        """V√≤ng l·∫∑p l·∫Øng nghe li√™n t·ª•c"""
        try:
            with sd.InputStream(
                device=self.mic_index,
                channels=1,
                samplerate=self.sample_rate,
                dtype='int16',
                blocksize=self.chunk_samples
            ) as stream:
                print("üéß ƒêang l·∫Øng nghe... (n√≥i g√¨ ƒë√≥ ƒë·ªÉ b·∫Øt ƒë·∫ßu thu √¢m)")

                while self.is_listening:
                    audio_chunk, overflowed = stream.read(self.chunk_samples)
                    if overflowed:
                        print("‚ö†Ô∏è Audio buffer overflow!")

                    if len(audio_chunk) > 0:
                        # Chuy·ªÉn ƒë·ªïi sang float32 cho VAD v√† √°p d·ª•ng chu·∫©n h√≥a bi√™n ƒë·ªô
                        audio_float = audio_chunk.astype(np.float32) / 32768.0

                        # # √Åp d·ª•ng gi·ªõi h·∫°n bi√™n ƒë·ªô ƒë·ªÉ tr√°nh ti·∫øng r√®
                        # max_amp = np.max(np.abs(audio_float))
                        # if max_amp > MAX_AMP:  # N·∫øu bi√™n ƒë·ªô qu√° l·ªõn
                        #     audio_float = audio_float * (MAX_AMP/ max_amp)

                        # X·ª≠ l√Ω VAD
                        vad_result = self.vad.process_audio_chunk(audio_float)

                        # G·ªçi callbacks
                        if self.on_speech_data:
                            self.on_speech_data(audio_chunk, int(
                                time.time() * 1000), vad_result)

                        if vad_result['action'] == 'speech_complete':
                            if self.on_speech_complete:
                                # Chuy·ªÉn ƒë·ªïi t·ª´ float32 v·ªÅ int16 ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªãnh d·∫°ng nh·∫•t qu√°n v·ªõi record_audio
                                audio_data = vad_result['audio_data']
                                int16_audio = (
                                    audio_data * 32768.0).astype(np.int16).tobytes()
                                self.on_speech_complete(
                                    int16_audio, vad_result['duration'])
                                # T·∫°o th∆∞ m·ª•c l∆∞u n·∫øu ch∆∞a c√≥
                                save_dir = "debug"
                                os.makedirs(save_dir, exist_ok=True)
                                file_path = os.path.join(
                                    BASE_DIR, save_dir, f"audio_mic.wav")
                                try:
                                    sf.write(
                                        file_path, vad_result['audio_data'], self.sample_rate, subtype='PCM_16')
                                    logger.debug(
                                        f"üíæ ƒê√£ l∆∞u file √¢m thanh: {file_path}")
                                except Exception as e:
                                    logger.error(
                                        f"‚ùå L·ªói khi l∆∞u file √¢m thanh: {e}")
                        elif vad_result['action'] == 'speaking' and not self.vad.is_speaking:
                            if self.on_speech_start:
                                self.on_speech_start()

        except Exception as e:
            print(f"‚ùå L·ªói l·∫Øng nghe: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.is_listening = False

    def __del__(self):
        self.stop_listening()

    def record_audio(self, duration_sec: float) -> bytes:
        """
        Ghi √¢m trong th·ªùi gian x√°c ƒë·ªãnh v√† tr·∫£ v·ªÅ d·ªØ li·ªáu √¢m thanh

        Args:
            duration_sec: Th·ªùi gian ghi √¢m (gi√¢y)

        Returns:
            bytes: D·ªØ li·ªáu √¢m thanh raw (PCM 16-bit)
        """
        print(f"üéôÔ∏è ƒêang ghi √¢m {duration_sec}s...")

        total_samples = int(self.sample_rate * duration_sec)
        recording = sd.rec(
            total_samples,
            samplerate=self.sample_rate,
            channels=1,
            dtype='int16',
            device=self.mic_index
        )
        sd.wait()

        audio_data = recording.reshape(-1).tobytes()
        print(f"‚úÖ Ghi √¢m ho√†n th√†nh - {len(audio_data)} bytes")
        return audio_data


class MQTTVoiceSender:
    """G·ª≠i √¢m thanh qua MQTT"""

    def __init__(self, mqtt_client: mqtt.Client, device_id: str):
        self.client = mqtt_client
        self.device_id = device_id
        self.topic_prefix = f"device/{device_id}/voice"

    def send_audio_file(self, audio_data: bytes, metadata: Dict[str, Any] = None):
        """
        G·ª≠i file √¢m thanh ho√†n ch·ªânh qua MQTT

        Args:
            audio_data: D·ªØ li·ªáu √¢m thanh raw
            metadata: Th√¥ng tin b·ªï sung (format, sample_rate, etc.)
        """
        if metadata is None:
            metadata = {}

        # Chia th√†nh chunks nh·ªè ƒë·ªÉ tr√°nh v∆∞·ª£t qu√° gi·ªõi h·∫°n MQTT
        chunk_size = 1024 * 8  # 8KB per chunk
        total_chunks = (len(audio_data) + chunk_size - 1) // chunk_size

        stream_id = f"voice_{int(time.time() * 1000)}"

        for i in range(total_chunks):
            start = i * chunk_size
            end = min(start + chunk_size, len(audio_data))
            chunk_data = audio_data[start:end]

            payload = {
                "deviceId": self.device_id,
                "streamId": stream_id,
                "chunkIndex": i,
                "totalChunks": total_chunks,
                "isLast": (i == total_chunks - 1),
                "timestamp": int(time.time() * 1000),
                "format": metadata.get("format", "pcm16le"),
                "sampleRate": metadata.get("sampleRate", 48000),
                "data": base64.b64encode(chunk_data).decode()
            }

            topic = f"{self.topic_prefix}/file"
            self.client.publish(topic, json.dumps(payload), qos=1)

        print(f"üì§ G·ª≠i file √¢m thanh qua MQTT - {total_chunks} chunks")

    def send_audio_stream(self, audio_chunk: bytes, timestamp: int, stream_id: str = None):
        """
        G·ª≠i chunk √¢m thanh real-time qua MQTT

        Args:
            audio_chunk: Chunk √¢m thanh
            timestamp: Timestamp c·ªßa chunk
            stream_id: ID c·ªßa stream (t·ª± t·∫°o n·∫øu None)
        """
        if stream_id is None:
            stream_id = f"stream_{int(time.time() * 1000)}"

        payload = {
            "deviceId": self.device_id,
            "streamId": stream_id,
            "timestamp": timestamp,
            "format": "pcm16le",
            "sampleRate": 48000,
            "data": base64.b64encode(audio_chunk).decode()
        }

        topic = f"{self.topic_prefix}/stream"
        self.client.publish(topic, json.dumps(payload), qos=0)


# ========== DEMO FUNCTIONS ==========


def demo_mqtt_streaming():
    """Demo g·ª≠i √¢m thanh qua MQTT"""
    print("=== Demo MQTT Voice Streaming ===")

    # Setup MQTT
    client = mqtt.Client()
    client.connect("localhost", 1883, 60)
    client.loop_start()

    mqtt_sender = MQTTVoiceSender(client, "jetson_001")
    streamer = VoiceStreamer("USB", sample_rate=48000)

    def on_speech_complete(audio_data, duration):
        print(f"ÔøΩÔøΩ G·ª≠i √¢m thanh qua MQTT: {duration:.1f}s")
        mqtt_sender.send_audio_file(audio_data, {
            "format": "pcm16le",
            "sampleRate": 48000,
            "duration": duration
        })

    streamer.set_callbacks(on_speech_complete=on_speech_complete)

    try:
        streamer.start_listening()
        print("üéß ƒêang l·∫Øng nghe v√† g·ª≠i qua MQTT...")

        while True:
            time.sleep(1)

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è D·ª´ng h·ªá th·ªëng...")
        streamer.stop_listening()
        client.loop_stop()
        client.disconnect()
