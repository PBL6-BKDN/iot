import time
import numpy as np
from typing import Dict, Any

from config import MAX_AMP


class VoiceActivityDetector:
    """PhÃ¡t hiá»‡n hoáº¡t Ä‘á»™ng giá»ng nÃ³i (Voice Activity Detection)"""

    def __init__(self, sample_rate: int = 48000, silence_threshold: float = 0.02,
                 silence_duration: float = 5.0, min_speech_duration: float = 0.5,
                 pre_buffer_duration: float = 0.2, post_buffer_duration: float = 0.2):
        """
        Args:
            sample_rate: Táº§n sá»‘ láº¥y máº«u
            silence_threshold: NgÆ°á»¡ng Ã¢m lÆ°á»£ng Ä‘á»ƒ coi lÃ  im láº·ng (0.0-1.0)
            silence_duration: Thá»i gian im láº·ng Ä‘á»ƒ káº¿t thÃºc thu Ã¢m (giÃ¢y)
            min_speech_duration: Thá»i gian nÃ³i tá»‘i thiá»ƒu Ä‘á»ƒ báº¯t Ä‘áº§u thu Ã¢m (giÃ¢y)
            pre_buffer_duration: Thá»i gian giá»¯ Ã¢m thanh trÆ°á»›c khi phÃ¡t hiá»‡n giá»ng nÃ³i (giÃ¢y)
            post_buffer_duration: Thá»i gian giá»¯ Ã¢m thanh sau khi im láº·ng (giÃ¢y)
        """
        self.sample_rate = sample_rate
        self.silence_threshold = silence_threshold
        self.silence_duration = silence_duration
        self.min_speech_duration = min_speech_duration
        self.pre_buffer_duration = pre_buffer_duration
        self.post_buffer_duration = post_buffer_duration

        # Tráº¡ng thÃ¡i
        self.is_speaking = False
        self.speech_start_time = None
        self.silence_start_time = None
        self.audio_buffer = []
        self.pre_buffer = []  # Buffer Ä‘á»ƒ giá»¯ Ã¢m thanh trÆ°á»›c khi phÃ¡t hiá»‡n giá»ng nÃ³i
        self.post_buffer = []  # Buffer Ä‘á»ƒ giá»¯ Ã¢m thanh sau khi im láº·ng

    def process_audio_chunk(self, audio_chunk: np.ndarray) -> Dict[str, Any]:
        """
        Xá»­ lÃ½ chunk Ã¢m thanh Ä‘á»ƒ phÃ¡t hiá»‡n giá»ng nÃ³i

        Args:
            audio_chunk: Chunk Ã¢m thanh (numpy array)

        Returns:
            Dict vá»›i thÃ´ng tin tráº¡ng thÃ¡i
        """
        # TÃ­nh RMS (Root Mean Square) Ä‘á»ƒ Ä‘o Ã¢m lÆ°á»£ng
        rms = np.sqrt(np.mean(audio_chunk.astype(np.float32) ** 2))

        current_time = time.time()

        # PhÃ¡t hiá»‡n giá»ng nÃ³i
        if rms > self.silence_threshold:
            if not self.is_speaking:
                # Báº¯t Ä‘áº§u nÃ³i - thÃªm pre_buffer vÃ o Ä‘áº§u
                self.is_speaking = True
                self.speech_start_time = current_time
                self.silence_start_time = None
                # Báº¯t Ä‘áº§u vá»›i pre_buffer (Ã¢m thanh trÆ°á»›c khi phÃ¡t hiá»‡n) + chunk hiá»‡n táº¡i
                self.audio_buffer = self.pre_buffer.copy() + [audio_chunk]
                self.post_buffer = []  # Reset post buffer
                print(f"ðŸ—£ï¸ Báº¯t Ä‘áº§u phÃ¡t hiá»‡n giá»ng nÃ³i (RMS: {rms:.4f}) - Pre-buffer: {len(self.pre_buffer)} chunks")
            else:
                # Äang nÃ³i - thÃªm vÃ o buffer
                self.audio_buffer.append(audio_chunk)
                self.silence_start_time = None
                self.post_buffer = []  # Reset post buffer khi cÃ²n Ä‘ang nÃ³i
        else:
            # Im láº·ng
            if self.is_speaking:
                # ThÃªm vÃ o post_buffer trong thá»i gian im láº·ng
                self.post_buffer.append(audio_chunk)
                
                if self.silence_start_time is None:
                    self.silence_start_time = current_time
                elif current_time - self.silence_start_time >= self.silence_duration:
                    # Káº¿t thÃºc nÃ³i - thÃªm post_buffer vÃ o cuá»‘i
                    speech_duration = current_time - self.speech_start_time
                    if speech_duration >= self.min_speech_duration:
                        # CÃ³ Ä‘á»§ thá»i gian nÃ³i
                        # ThÃªm post_buffer vÃ o cuá»‘i (nhÆ°ng chá»‰ láº¥y post_buffer_duration)
                        all_audio = self.audio_buffer + self.post_buffer
                        
                        # Chuáº©n hÃ³a biÃªn Ä‘á»™ Ã¢m thanh trÆ°á»›c khi ná»‘i
                        normalized_buffers = []
                        for chunk in all_audio:
                            normalized_buffers.append(chunk)

                        audio_data = np.concatenate(normalized_buffers)

                        # Äáº£m báº£o audio_data lÃ  máº£ng 1 chiá»u
                        if len(audio_data.shape) > 1:
                            audio_data = audio_data.flatten()

                        self.is_speaking = False
                        self.speech_start_time = None
                        self.silence_start_time = None
                        self.audio_buffer = []
                        self.post_buffer = []

                        print(f"âœ… HoÃ n táº¥t thu Ã¢m ({speech_duration:.1f}s) - Tá»•ng chunks: {len(all_audio)}")
                        return {
                            'action': 'speech_complete',
                            'audio_data': audio_data,
                            'duration': speech_duration,
                            'rms': rms
                        }
                    else:
                        # Thá»i gian nÃ³i quÃ¡ ngáº¯n - bá» qua
                        print(
                            f"âš ï¸ Thá»i gian nÃ³i quÃ¡ ngáº¯n ({speech_duration:.1f}s) - bá» qua")
                        self.is_speaking = False
                        self.speech_start_time = None
                        self.silence_start_time = None
                        self.audio_buffer = []
                        self.post_buffer = []
            else:
                # Äang im láº·ng vÃ  chÆ°a phÃ¡t hiá»‡n giá»ng nÃ³i - giá»¯ trong pre_buffer
                # TÃ­nh sá»‘ chunks cáº§n giá»¯ dá»±a trÃªn pre_buffer_duration
                # TÃ­nh thá»i gian cá»§a má»—i chunk (giÃ¢y)
                chunk_duration = len(audio_chunk) / self.sample_rate
                # TÃ­nh sá»‘ chunks cáº§n giá»¯ (lÃ m trÃ²n lÃªn Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»§ thá»i gian)
                import math
                max_pre_chunks = max(1, math.ceil(self.pre_buffer_duration / chunk_duration))
                self.pre_buffer.append(audio_chunk)
                # Giá»¯ pre_buffer trong giá»›i háº¡n
                if len(self.pre_buffer) > max_pre_chunks:
                    self.pre_buffer = self.pre_buffer[-max_pre_chunks:]

        return {
            'action': 'listening' if not self.is_speaking else 'speaking',
            'is_speaking': self.is_speaking,
            'rms': rms,
            'speech_duration': current_time - self.speech_start_time if self.is_speaking else 0
        }
